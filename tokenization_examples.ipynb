{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FJYdr-kGfZvq",
        "bxoLPbIDblPN",
        "XZXlK-nvfySx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Tokenization Examples"
      ],
      "metadata": {
        "id": "FJYdr-kGfZvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3SXdwPZF6Bg",
        "outputId": "7caebdda-4b22-4477-82f3-cd618786d721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY1fHu7fF2zd"
      },
      "outputs": [],
      "source": [
        "sentence = \"Historically these two events are connected, although I still don't know how.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = word_tokenize(sentence)\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9Ohk07sGFsV",
        "outputId": "ab66452f-0767-4338-b98e-0690a2ceed96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Historically', 'these', 'two', 'events', 'are', 'connected', ',', 'although', 'I', 'still', 'do', \"n't\", 'know', 'how', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ps_stem_sent = [ps.stem(words_sent) for words_sent in sent]\n",
        "print(ps_stem_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4haRI_nGNRG",
        "outputId": "1af8b7a5-d04c-4679-da40-e044fceae770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['histor', 'these', 'two', 'event', 'are', 'connect', ',', 'although', 'i', 'still', 'do', \"n't\", 'know', 'how', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lem_sent = [lemmatizer.lemmatize(words_sent) for words_sent in sent]\n",
        "print(lem_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Haxn0RGR9E",
        "outputId": "ffb2e32f-372c-4b00-d955-fd91e2c677bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Historically', 'these', 'two', 'event', 'are', 'connected', ',', 'although', 'I', 'still', 'do', \"n't\", 'know', 'how', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycNay6SukEoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(sentence)\n",
        "print([token.lemma_ for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xdBOFQGKSm9",
        "outputId": "e7ce1280-a43d-4a75-fe21-9b8f2068ac24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['historically', 'these', 'two', 'event', 'be', 'connect', ',', 'although', 'I', 'still', 'do', 'not', 'know', 'how', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPE Tokenization First Iteration Example"
      ],
      "metadata": {
        "id": "bxoLPbIDblPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = 'leef low low low low lower lower widest widest widest newest newest newest newest newest'\n",
        "\n",
        "pre_tokens = corpus.split(' ')\n",
        "pre_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTE4HNNSYUsY",
        "outputId": "c71560e4-9b00-491a-8231-95669677070a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['leef',\n",
              " 'low',\n",
              " 'low',\n",
              " 'low',\n",
              " 'low',\n",
              " 'lower',\n",
              " 'lower',\n",
              " 'widest',\n",
              " 'widest',\n",
              " 'widest',\n",
              " 'newest',\n",
              " 'newest',\n",
              " 'newest',\n",
              " 'newest',\n",
              " 'newest']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EOW = '</w>'\n",
        "\n",
        "text = [[*[c for c in w], EOW] for w in pre_tokens]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxQhkiXvYZwn",
        "outputId": "216be9d3-6da0-4c8e-cf8e-c2e58c962542"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['l', 'e', 'e', 'f', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', 'e', 'r', '</w>'],\n",
              " ['l', 'o', 'w', 'e', 'r', '</w>'],\n",
              " ['w', 'i', 'd', 'e', 's', 't', '</w>'],\n",
              " ['w', 'i', 'd', 'e', 's', 't', '</w>'],\n",
              " ['w', 'i', 'd', 'e', 's', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'e', 's', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'e', 's', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'e', 's', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'e', 's', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'e', 's', 't', '</w>']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import itertools\n",
        "\n",
        "\n",
        "def unpack_sublists(sublists):\n",
        "    return list(itertools.chain.from_iterable(sublists))\n",
        "\n",
        "def get_vocab(text):\n",
        "    return collections.Counter(unpack_sublists(text))\n",
        "\n",
        "vocab = get_vocab(text)\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6WpxWSTYfJX",
        "outputId": "f42e1bfb-d6f1-4a50-c6ae-d809aa173304"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'l': 7,\n",
              "         'e': 17,\n",
              "         'f': 1,\n",
              "         '</w>': 15,\n",
              "         'o': 6,\n",
              "         'w': 14,\n",
              "         'r': 2,\n",
              "         'i': 3,\n",
              "         'd': 3,\n",
              "         's': 8,\n",
              "         't': 8,\n",
              "         'n': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairs(text):\n",
        "    pairs = collections.defaultdict(int)\n",
        "    for w in text:\n",
        "        for i in range(len(w)-1):\n",
        "            pairs[w[i], w[i+1]] += 1\n",
        "    return pairs\n",
        "\n",
        "get_pairs(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaQOSMAxYiy_",
        "outputId": "585e4914-f66f-4191-ae1c-539f813754f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('l', 'e'): 1,\n",
              "             ('e', 'e'): 1,\n",
              "             ('e', 'f'): 1,\n",
              "             ('f', '</w>'): 1,\n",
              "             ('l', 'o'): 6,\n",
              "             ('o', 'w'): 6,\n",
              "             ('w', '</w>'): 4,\n",
              "             ('w', 'e'): 7,\n",
              "             ('e', 'r'): 2,\n",
              "             ('r', '</w>'): 2,\n",
              "             ('w', 'i'): 3,\n",
              "             ('i', 'd'): 3,\n",
              "             ('d', 'e'): 3,\n",
              "             ('e', 's'): 8,\n",
              "             ('s', 't'): 8,\n",
              "             ('t', '</w>'): 8,\n",
              "             ('n', 'e'): 5,\n",
              "             ('e', 'w'): 5})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(get_pairs(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1umKRy3easo1",
        "outputId": "0d634787-9f20-479a-ecea-7c78a7c6dd42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = get_pairs(text)\n",
        "best = max(pairs, key=pairs.get)\n",
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akY61aO5YsXQ",
        "outputId": "fe39ec3a-2fc2-4af1-af8d-d2368b97bb1e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('e', 's')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "\n",
        "def merge_pair_tokens(text, pair):\n",
        "    # Change text\n",
        "    new_text = copy.deepcopy(text)\n",
        "    for w in new_text:\n",
        "        for i in range(len(w)-1):\n",
        "            if w[i] == pair[0] and w[i+1] == pair[1]:\n",
        "                w[i] += w.pop(i+1)\n",
        "    return new_text\n",
        "\n",
        "new_text = merge_pair_tokens(text, best)\n",
        "new_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQcgVl4_Yv6f",
        "outputId": "56254008-7c5f-4642-c181-b8d4599bfdf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['l', 'e', 'e', 'f', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', '</w>'],\n",
              " ['l', 'o', 'w', 'e', 'r', '</w>'],\n",
              " ['l', 'o', 'w', 'e', 'r', '</w>'],\n",
              " ['w', 'i', 'd', 'es', 't', '</w>'],\n",
              " ['w', 'i', 'd', 'es', 't', '</w>'],\n",
              " ['w', 'i', 'd', 'es', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'es', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'es', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'es', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'es', 't', '</w>'],\n",
              " ['n', 'e', 'w', 'es', 't', '</w>']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_vocab(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ae-O8Myc1VA",
        "outputId": "a7eca3c3-f95b-44c9-c2c4-462cf582ad67"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'l': 7,\n",
              "         'e': 9,\n",
              "         'f': 1,\n",
              "         '</w>': 15,\n",
              "         'o': 6,\n",
              "         'w': 14,\n",
              "         'r': 2,\n",
              "         'i': 3,\n",
              "         'd': 3,\n",
              "         'es': 8,\n",
              "         't': 8,\n",
              "         'n': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'|'.join(unpack_sublists(new_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9JX7EXrzYQiZ",
        "outputId": "2735da12-620a-4249-e5fc-5257c40788e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'l|e|e|f|</w>|l|o|w|</w>|l|o|w|</w>|l|o|w|</w>|l|o|w|</w>|l|o|w|e|r|</w>|l|o|w|e|r|</w>|w|i|d|es|t|</w>|w|i|d|es|t|</w>|w|i|d|es|t|</w>|n|e|w|es|t|</w>|n|e|w|es|t|</w>|n|e|w|es|t|</w>|n|e|w|es|t|</w>|n|e|w|es|t|</w>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Byte-Level BPE (BBPE) Tokenizers Comparison\n",
        "This work is inspired by the paper \"[How Good is Your Tokenizer?\n",
        "On the Monolingual Performance of Multilingual Language Models](https://aclanthology.org/2021.acl-long.243/)\"."
      ],
      "metadata": {
        "id": "XZXlK-nvfySx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Donwload Italian-English European Parliament Proceedings Parallel Corpus\n",
        "Reference [here](https://www.statmt.org/europarl/)."
      ],
      "metadata": {
        "id": "_b9VEH5Ofnhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.statmt.org/europarl/v7/it-en.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXYpE_qNhSX5",
        "outputId": "eed4f773-311b-4759-aca5-a531adb20353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-20 16:32:45--  https://www.statmt.org/europarl/v7/it-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 196722035 (188M) [application/x-gzip]\n",
            "Saving to: ‘it-en.tgz.1’\n",
            "\n",
            "it-en.tgz.1         100%[===================>] 187.61M  2.17MB/s    in 85s     \n",
            "\n",
            "2023-06-20 16:34:11 (2.21 MB/s) - ‘it-en.tgz.1’ saved [196722035/196722035]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar zxvf it-en.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Jw2YhAXgdV",
        "outputId": "71e46bb3-3d8c-4843-a403-34ed31b3ddd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "europarl-v7.it-en.en\n",
            "europarl-v7.it-en.it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1n7YvMTfI55",
        "outputId": "2d4c3e62-c9a4-40b4-e909-f74c69029bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 990M\n",
            "drwxr-xr-x 1 root root  4.0K Jun 20 16:34 .\n",
            "drwxr-xr-x 1 root root  4.0K Jun 20 15:54 ..\n",
            "drwxr-xr-x 4 root root  4.0K Jun 14 18:26 .config\n",
            "-rw-r--r-- 1 1026 users 285M May 15  2012 europarl-v7.it-en.en\n",
            "-rw-r--r-- 1 1026 users 311M May 15  2012 europarl-v7.it-en.it\n",
            "-rw-r--r-- 1 root root  188M May 16  2012 it-en.tgz\n",
            "-rw-r--r-- 1 root root  188M May 16  2012 it-en.tgz.1\n",
            "drwxr-xr-x 1 root root  4.0K Jun 14 18:27 sample_data\n",
            "drwxr-xr-x 2 root root  4.0K Jun 20 15:58 tokenizer_it\n",
            "-rw-r--r-- 1 root root  4.8M Jun 20 16:26 train_europarl-v7.it-en.en\n",
            "-rw-r--r-- 1 root root  4.8M Jun 20 16:26 train_europarl-v7.it-en.it\n",
            "-rw-r--r-- 1 root root  4.8M Jun 20 15:57 trunc_europarl-v7.it-en.en\n",
            "-rw-r--r-- 1 root root  4.8M Jun 20 15:57 trunc_europarl-v7.it-en.it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -25 europarl-v7.it-en.it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mgSdj9OfOXW",
        "outputId": "43c96b59-2a77-433a-b977-c6237f4c004d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ripresa della sessione\n",
            "Dichiaro ripresa la sessione del Parlamento europeo, interrotta venerdì 17 dicembre e rinnovo a tutti i miei migliori auguri nella speranza che abbiate trascorso delle buone vacanze.\n",
            "Come avrete avuto modo di constatare il grande \"baco del millennio\" non si è materializzato. Invece, i cittadini di alcuni nostri paesi sono stati colpiti da catastrofi naturali di proporzioni davvero terribili.\n",
            "Avete chiesto che si tenesse una discussione su tale tema nei prossimi giorni, nel corso della presente tornata.\n",
            "Nel frattempo è mio desiderio, come del resto mi è stato chiesto da alcuni colleghi, osservare un minuto di silenzio in memoria di tutte le vittime delle tempeste che si sono abbattute sui diversi paesi dell' Unione europea.\n",
            "Vi invito pertanto ad alzarvi in piedi per osservare appunto un minuto di silenzio.\n",
            "(Il Parlamento osserva un minuto di silenzio)\n",
            "Signora Presidente, intervengo per una mozione d'ordine.\n",
            "Come avrà letto sui giornali o sentito alla televisione, in Sri Lanka si sono verificati numerosi assassinii ed esplosioni di ordigni.\n",
            "Una delle vittime più recenti è stato Kumar Ponnambalam, che qualche mese fa era venuto in visita qui al Parlamento europeo.\n",
            "Signora Presidente, sarebbe opportuno che inviasse una lettera alla Presidente del Sri Lanka per esprimere le condoglianze del Parlamento per questa e le altre morti violente verificatesi in Sri Lanka e per invitarla a fare quanto in suo potere al fine di giungere a una riconciliazione pacifica in questa situazione assai difficile.\n",
            "Sì, onorevole Evans, ritengo che un' iniziativa del tipo che lei propone sia assolutamente opportuna.\n",
            "Se l' Assemblea è d' accordo seguirò il suggerimento dell' onorevole Evans.\n",
            "Signora Presidente, un richiamo al Regolamento.\n",
            "Gradirei avere il suo parere riguardo all'articolo 143 sull'inammissibilità.\n",
            "La mia domanda si ricollega a un tema all'ordine del giorno di giovedì e che formulerò di nuovo al momento opportuno.\n",
            "La relazione Cunha sui programmi di orientamento pluriennali è iscritta all'ordine del giorno della Plenaria di giovedì e al paragrafo 6 contiene una proposta volta a introdurre una sorta di sanzione a carico delle quote di quei paesi che non riescono a raggiungere i loro obiettivi di riduzione annuali delle flotte, nonostante il principio della stabilità relativa.\n",
            "Credo che tale principio sia un principio giuridico fondamentale della politica comune della pesca e qualsiasi proposta volta a sovvertirlo sarebbe giuridicamente inammissibile Vorrei sapere se è possibile sollevare un'obiezione di questo tipo nel contesto di una semplice relazione, e non di una proposta legislativa, e se rientra nelle mie competenze sollevare una tale obiezione giovedì prossimo.\n",
            "E' appunto in quell' occasione che, se lo desidera, avrà modo di sollevare la sua questione pregiudiziale, cioè giovedì in apertura della discussione sulla relazione.\n",
            "Signora Presidente, in coincidenza con la prima tornata dell'anno del Parlamento europeo, negli Stati Uniti in Texas è stata fissata, purtroppo per giovedì prossimo, l'esecuzione di un condannato a morte, un giovane di 34 anni che chiameremo di nome Hicks.\n",
            "Su richiesta di un deputato francese, l'onorevole Zimeray, è già stata presentata una petizione, che ha avuto molti firmatari tra cui il sottoscritto, ma le chiedo, in conformità con l'indirizzo ormai costantemente espresso dal Parlamento europeo e da tutta la Comunità europea, di intervenire, con il prestigio della sua carica e dell'Istituzione che lei rappresenta, presso il Presidente e il Governatore del Texas Bush, che ha il potere di sospendere la condanna a morte e di graziare il condannato.\n",
            "E tutto ciò in conformità con i principi che abbiamo sempre sostenuto.\n",
            "La ringrazio, onorevole Segni, lo farò volentieri.\n",
            "In effetti ciò è assolutamente conforme alla posizione che il nostro Parlamento ha sempre sostenuto.\n",
            "Signora Presidente, vorrei richiamare l'attenzione su un caso che il Parlamento segue da tempo, ossia il caso di Alexander Nikitin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -25 europarl-v7.it-en.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzI9F1e7Uq-H",
        "outputId": "9f54106d-07fc-49cb-8eb4-ecfadff4da4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumption of the session\n",
            "I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
            "Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
            "You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
            "In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
            "Please rise, then, for this minute' s silence.\n",
            "(The House rose and observed a minute' s silence)\n",
            "Madam President, on a point of order.\n",
            "You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.\n",
            "One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.\n",
            "Would it be appropriate for you, Madam President, to write a letter to the Sri Lankan President expressing Parliament's regret at his and the other violent deaths in Sri Lanka and urging her to do everything she possibly can to seek a peaceful reconciliation to a very difficult situation?\n",
            "Yes, Mr Evans, I feel an initiative of the type you have just suggested would be entirely appropriate.\n",
            "If the House agrees, I shall do as Mr Evans has suggested.\n",
            "Madam President, on a point of order.\n",
            "I would like your advice about Rule 143 concerning inadmissibility.\n",
            "My question relates to something that will come up on Thursday and which I will then raise again.\n",
            "The Cunha report on multiannual guidance programmes comes before Parliament on Thursday and contains a proposal in paragraph 6 that a form of quota penalties should be introduced for countries which fail to meet their fleet reduction targets annually. It says that this should be done despite the principle of relative stability.\n",
            "I believe that the principle of relative stability is a fundamental legal principle of the common fisheries policy and a proposal to subvert it would be legally inadmissible. I want to know whether one can raise an objection of that kind to what is merely a report, not a legislative proposal, and whether that is something I can competently do on Thursday.\n",
            "That is precisely the time when you may, if you wish, raise this question, i.e. on Thursday prior to the start of the presentation of the report.\n",
            "Madam President, coinciding with this year' s first part-session of the European Parliament, a date has been set, unfortunately for next Thursday, in Texas in America, for the execution of a young 34 year-old man who has been sentenced to death. We shall call him Mr Hicks.\n",
            "At the request of a French Member, Mr Zimeray, a petition has already been presented, which many people signed, including myself. However, I would ask you, in accordance with the line which is now constantly followed by the European Parliament and by the whole of the European Community, to make representations, using the weight of your prestigious office and the institution you represent, to the President and to the Governor of Texas, Mr Bush, who has the power to order a stay of execution and to reprieve the condemned person.\n",
            "This is all in accordance with the principles that we have always upheld.\n",
            "Thank you, Mr Segni, I shall do so gladly.\n",
            "Indeed, it is quite in keeping with the positions this House has always adopted.\n",
            "Madam President, I should like to draw your attention to a case in which this Parliament has consistently shown an interest. It is the case of Alexander Nikitin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KEEPING ONLY PART OF THE TEXT TO SPEED UP THE NOTEBOOK**"
      ],
      "metadata": {
        "id": "HQPI3pTcWWUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "TEXT_SIZE = 5_000_000\n",
        "\n",
        "FILE_EN_PATH = Path('europarl-v7.it-en.en')\n",
        "TRAIN_FILE_EN_PATH = Path('train_europarl-v7.it-en.en')\n",
        "\n",
        "FILE_IT_PATH = Path('europarl-v7.it-en.it')\n",
        "TRAIN_FILE_IT_PATH = Path('train_europarl-v7.it-en.it')"
      ],
      "metadata": {
        "id": "eB5_oYWca5Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text [EN] (298M chars total)\n",
        "with FILE_EN_PATH.open('r') as f:\n",
        "    text_en_tmp = f.read(TEXT_SIZE*2)\n",
        "    text_en = text_en_tmp[:TEXT_SIZE]\n",
        "    text_en_test = text_en_tmp[TEXT_SIZE:]\n",
        "\n",
        "# Read text [IT] (322M chars total)\n",
        "with FILE_IT_PATH.open('r') as f:\n",
        "    text_it_tmp = f.read(TEXT_SIZE*2)\n",
        "    text_it = text_it_tmp[:TEXT_SIZE]\n",
        "    text_it_test = text_it_tmp[TEXT_SIZE:]"
      ],
      "metadata": {
        "id": "YF6RIExXgdWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write train text [EN]\n",
        "with TRAIN_FILE_EN_PATH.open(\"a\") as f:\n",
        "    f.write(text_en)\n",
        "\n",
        "# Write train text [IT]\n",
        "with TRAIN_FILE_IT_PATH.open(\"a\") as f:\n",
        "    f.write(text_it)"
      ],
      "metadata": {
        "id": "ZYVF_dAJdBRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_en[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PRrolh9PVhOf",
        "outputId": "ea93c2fe-54a6-4cb4-aa03-6a1fc2f41610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Frid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_it[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eVHHPI5vVFJx",
        "outputId": "3de8810b-d772-4465-e8cf-6e7c77da0d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ripresa della sessione\\nDichiaro ripresa la sessione del Parlamento europeo, interrotta venerdì 17 di'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**...some text pre-processing is needed**"
      ],
      "metadata": {
        "id": "1y4_J9LVf0iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrive GPT-2 BBPE tokenizer\n",
        "This tokenizer has been trained to treat spaces like parts of the tokens so a word will be encoded differently whether it is at the beginning of the sentence (without space) or not.\n",
        "\n",
        "Reference [here](https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2TokenizerFast)."
      ],
      "metadata": {
        "id": "KIv8_owbT8KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYHqESv3f-5I",
        "outputId": "5846e794-ec62-4a66-fdc2-b333dc077dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "\n",
        "pretrained_weights = 'gpt2'\n",
        "tokenizer_en = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
        "# tokenizer_en.pad_token = tokenizer_en.eos_token"
      ],
      "metadata": {
        "id": "r0PXJd66Qz16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how the pre-tokenizer works\n",
        "tokenizer_en.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text_en[:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taKiP9KPZypJ",
        "outputId": "ebcee319-6fe6-478c-9c18-e0a1c8ca9e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Resumption', (0, 10)),\n",
              " ('Ġof', (10, 13)),\n",
              " ('Ġthe', (13, 17)),\n",
              " ('Ġsession', (17, 25)),\n",
              " ('Ċ', (25, 26)),\n",
              " ('I', (26, 27)),\n",
              " ('Ġdeclare', (27, 35)),\n",
              " ('Ġresumed', (35, 43)),\n",
              " ('Ġthe', (43, 47)),\n",
              " ('Ġsession', (47, 55)),\n",
              " ('Ġof', (55, 58)),\n",
              " ('Ġthe', (58, 62)),\n",
              " ('ĠEuropean', (62, 71)),\n",
              " ('ĠParliament', (71, 82)),\n",
              " ('Ġadjourned', (82, 92)),\n",
              " ('Ġon', (92, 95)),\n",
              " ('ĠFriday', (95, 102)),\n",
              " ('Ġ17', (102, 105)),\n",
              " ('ĠDecember', (105, 114)),\n",
              " ('Ġ1999', (114, 119)),\n",
              " (',', (119, 120)),\n",
              " ('Ġand', (120, 124)),\n",
              " ('ĠI', (124, 126)),\n",
              " ('Ġwould', (126, 132)),\n",
              " ('Ġlike', (132, 137)),\n",
              " ('Ġonce', (137, 142)),\n",
              " ('Ġagain', (142, 148)),\n",
              " ('Ġt', (148, 150))]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_toks_ids = tokenizer_en.encode(text_en)\n",
        "text_en_decoded = tokenizer_en.decode(en_toks_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr4yE7Emgb-q",
        "outputId": "664bb0f0-c0ab-4ec3-d0b4-54f6b87641f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (999130 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_toks_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZtyWy3-VrHx",
        "outputId": "a62f6bcb-c3e9-4536-896e-446e2eb36cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999130"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create custom Italian BBPE tokenizer\n",
        "\n",
        "Reference [here](https://github.com/huggingface/tokenizers/blob/main/bindings/python/py_src/tokenizers/implementations/byte_level_bpe.py)."
      ],
      "metadata": {
        "id": "M4eDqtL-U_ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "\n",
        "TOKENIZER_IT_FILE_PATH = Path('./tokenizer_it')\n",
        "\n",
        "\n",
        "tokenizer_it = ByteLevelBPETokenizer()"
      ],
      "metadata": {
        "id": "lIgmq6UZVQhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "# Customize training with <|endoftext|> special GPT2 token and use the same vocab. size\n",
        "tokenizer_it.train(\n",
        "    files=str(TRAIN_FILE_IT_PATH),\n",
        "    vocab_size=tokenizer_en.vocab_size,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"<|endoftext|>\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwsM7ScObi57",
        "outputId": "f6146361-6d25-4fd7-a643-3a358480ef7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.62 s ± 1.48 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokenizer\n",
        "TOKENIZER_IT_FILE_PATH.mkdir(exist_ok=True, parents=True)\n",
        "tokenizer_it.save_model(str(TOKENIZER_IT_FILE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVEpkWbmblFQ",
        "outputId": "736486ca-4212-4017-820a-e6a0e1943332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenizer_it/vocab.json', 'tokenizer_it/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare tokenizers on Italian text\n",
        "Use the subword fertility and the proportion of continued words metrics as done in the [original paper](https://aclanthology.org/2021.acl-long.243/)."
      ],
      "metadata": {
        "id": "RKNha47Ch8NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.it import Italian\n",
        "\n",
        "\n",
        "nlp = Italian()\n",
        "pre_tokenizer_it = nlp.tokenizer"
      ],
      "metadata": {
        "id": "JZ8p50mGkXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the test segment of corpus**"
      ],
      "metadata": {
        "id": "oFAbTEs9pelv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_it = pre_tokenizer_it(text_it_test)\n",
        "num_words_it = len(words_it)"
      ],
      "metadata": {
        "id": "dDuuTQ55kc5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sub-word fertility**: how aggressively a tokenizer splits words? (*The higher the worst*)"
      ],
      "metadata": {
        "id": "OTgMwM_5mYJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_en = tokenizer_en.encode(text_it)\n",
        "tokens_it = tokenizer_it.encode(text_it)"
      ],
      "metadata": {
        "id": "GaXImKxWlj-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subword_fertility_en = len(tokens_en) / num_words_it\n",
        "subword_fertility_it = len(tokens_it) / num_words_it\n",
        "\n",
        "subword_fertility_en, subword_fertility_it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkAzVpN5lnAt",
        "outputId": "eaf8915f-0194-4abf-c9ff-8b3c44675110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.9703256591368599, 1.016110029448685)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proportion of continued words**: how often a tokenizer splits words?  (*The higher the worst*)"
      ],
      "metadata": {
        "id": "TYyEi9dImiuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_tokens_en = sum([1 if len(tokenizer_en.encode(str(w))) > 1 else 0 for w in words_it])\n",
        "complete_tokens_it = sum([1 if len(tokenizer_it.encode(str(w))) > 1 else 0 for w in words_it])"
      ],
      "metadata": {
        "id": "s9F_4f3qmt3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pocws_en = complete_tokens_en / num_words_it\n",
        "pocws_it = complete_tokens_it / num_words_it\n",
        "\n",
        "pocws_en, pocws_it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw01DVTdnuhm",
        "outputId": "9d08c4d8-cf1f-46c8-d190-d656ea22cd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.560793901162639, 0.361889977355016)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BM0dFdV9qq4D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}