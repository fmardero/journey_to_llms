{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments using Langchain & OpenAI models"
      ],
      "metadata": {
        "id": "Sm9XG4dLG4js"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "czz8Qzlw-Dna"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai langchain duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can get your OpenAI API key from [here](https://platform.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "Ty3tAD1lHjtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = input('Enter your OpenAI API key:')"
      ],
      "metadata": {
        "id": "LfOkcZky-MFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "Ol9jlGRh-YrN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find all the OpenAI models available [here](https://platform.openai.com/docs/models).\n",
        "\n",
        "Try to change the temperature parameter to test the output variability."
      ],
      "metadata": {
        "id": "ZtR3AZf7ITM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(\n",
        "    model_name='text-davinci-003',\n",
        "    temperature=0.9,\n",
        "    max_tokens=256,\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "U5mxNKkD-axU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Explain antibiotics.'\n",
        "\n",
        "for i in range(3):\n",
        "    print(f'Output {i}')\n",
        "    print(textwrap.fill(llm(prompt), 80))\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2cRYmKr-sjp",
        "outputId": "1149c317-168a-4750-8c86-7e9aba5f3a2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output 0\n",
            "  Antibiotics are a type of medication used to treat bacterial infections. They\n",
            "work by either killing the bacteria or stopping them from reproducing and\n",
            "spreading. They are not effective against viral infections. Commonly prescribed\n",
            "antibiotics include penicillin, tetracycline, and vancomycin. Overuse or misuse\n",
            "of antibiotics can cause them to become less effective in treating bacterial\n",
            "infections, a phenomenon known as antibiotic resistance.\n",
            "\n",
            "\n",
            "\n",
            "Output 1\n",
            "  Antibiotics are drugs used to prevent or kill bacterial infections.\n",
            "Antibiotics work by keeping bacteria from reproducing or by killing the bacteria\n",
            "outright. They do not work against viruses. Antibiotics are generally prescribed\n",
            "to treat infections caused by bacteria, but they can also be used to prevent\n",
            "infections or to treat certain conditions where there may be a risk of bacterial\n",
            "infection.\n",
            "\n",
            "\n",
            "\n",
            "Output 2\n",
            "  Antibiotics are medications used to fight infections caused by bacteria. They\n",
            "work by either killing or stopping the growth of bacteria in the body.\n",
            "Antibiotics can be taken orally or administered intravenously (through a vein)\n",
            "by injection.  Antibiotics treat infections caused by bacteria, not viruses. It\n",
            "is important to know the difference between viral and bacterial infections.\n",
            "Viral infections, such as the common cold and flu, cannot be treated with\n",
            "antibiotics. While there are drugs that can help relieve symptoms of a viral\n",
            "infection, antibiotics will not work against a virus. It is important to take\n",
            "antibiotics only when prescribed by your doctor or health care provider and to\n",
            "complete the entire course of treatment as prescribed. Taking an antibiotic for\n",
            "too short a time or skipping doses can lead to drug resistance, making the\n",
            "antibiotic less effective.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting and in-context learning"
      ],
      "metadata": {
        "id": "3h4cl-2m-wOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import (\n",
        "    PromptTemplate,\n",
        "    FewShotPromptTemplate,\n",
        ")\n",
        "from langchain.chains import (\n",
        "    LLMChain,\n",
        "    PALChain,\n",
        "    SimpleSequentialChain,\n",
        "    SequentialChain,\n",
        ")"
      ],
      "metadata": {
        "id": "IM9Bsdzl-03n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot in-context learning"
      ],
      "metadata": {
        "id": "i8sVl3G2B8XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are a history teacher.\n",
        "\n",
        "Return a list of historical events. Each event must be described shortly, in historical order. Providing dates, return only the year, not the day or the month. The events shoud relate to the given topic.\n",
        "\n",
        "The topic relates to {topic}.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3Tgx8e9c-xJm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['topic'],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "AEpIzaF6-3M0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_1 = 'the Greek economic crisis in 2009'\n",
        "topic_2 = 'the liberation of Italy from Nazism and Fascism'"
      ],
      "metadata": {
        "id": "IKYiFMN7_B2U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check what the prompt will be like\n",
        "print(textwrap.fill(prompt_template.format(topic=topic_1), 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVsyyuMe_Dkz",
        "outputId": "b2d27e33-b885-4b03-9567-229dc61078ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You are a history teacher.  Return a list of historical events. Each event must\n",
            "be described shortly, in historical order. Providing dates, return only the\n",
            "year, not the day or the month. The events shoud relate to the given topic.  The\n",
            "topic relates to the Greek economic crisis in 2009.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "nNozGNtM_J21"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain specifying the input variable to use in the prompt\n",
        "print(chain.run(topic_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCX5RGF9_Nt8",
        "outputId": "3fc5680c-d691-4290-fae6-7aa589b89ad6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. 1919: Formation of the Fascist militia in Italy \n",
            "2. 1922: March on Rome - Mussolini and his Fascist militia seize control of the Italian government \n",
            "3. 1937: Italy invades and annexes Ethiopia \n",
            "4. 1940: Italy joins the Axis powers \n",
            "5. 1943: Allied invasion of Sicily \n",
            "6. 1943: Fall of Fascist government and Mussolini deposed \n",
            "7. 1944: Allied forces enter Rome \n",
            "8. 1945: German forces in Italy surrender \n",
            "9. 1946: The Italian Republic is established, officially marking the end of Fascism and Nazism in Italy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot in-context learning"
      ],
      "metadata": {
        "id": "7F3vexWcCFUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of few-shot examples\n",
        "examples = [\n",
        "    {\n",
        "        'comment': 'Great service for an affordable price. We will definitely be booking again.',\n",
        "        'sentiment': '<positive>',\n",
        "    },\n",
        "    {\n",
        "        'comment': 'Just booked two nights at this hotel.',\n",
        "        'sentiment': '<neural>',\n",
        "    },\n",
        "    {\n",
        "        'comment': 'Horrible service. The room was dirty and unpleasant.',\n",
        "        'sentiment': '<negative>',\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "ac0bzpTGCPJm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the prompt template template\n",
        "few_shot_template = \"\"\"\n",
        "Comment: {comment}\n",
        "Sentiment: {sentiment}\\n\n",
        "\"\"\"\n",
        "\n",
        "sentiment_analysis_prompt = PromptTemplate(\n",
        "    input_variables=['comment', 'sentiment'],\n",
        "    template=few_shot_template,\n",
        ")"
      ],
      "metadata": {
        "id": "uB97bbx8DU3r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    # These are the examples we want to insert into the prompt.\n",
        "    examples=examples,\n",
        "    # This is how we want to format the examples when we insert them into the prompt.\n",
        "    example_prompt=sentiment_analysis_prompt,\n",
        "    # The prefix is some text that goes before the examples in the prompt.\n",
        "    # Usually, this consists of intructions.\n",
        "    prefix='Provide the sentiment of this comment',\n",
        "    # The suffix is some text that goes after the examples in the prompt.\n",
        "    # Usually, this is where the user input will go\n",
        "    suffix=\"Comment: {input}\\nSentiment:\",\n",
        "    # The input variables are the variables that the overall prompt expects.\n",
        "    input_variables=['input'],\n",
        "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with\n",
        "    example_separator=\"\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "id": "vks2TIkmDwQx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_1 = 'Amazing experience! The pool was very cool!'\n",
        "comment_2 = 'Everything ok, but it rained the whole weekend.'\n",
        "comment_3 = 'Totally dissatisfied by the service.'"
      ],
      "metadata": {
        "id": "ffN_82WOERHp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now generate a prompt using the `format` method.\n",
        "print(few_shot_prompt.format(input=comment_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR6ow5_6EIKu",
        "outputId": "af32fcb3-fa7b-48d4-be5f-27a86e2b166e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide the sentiment of this comment\n",
            "\n",
            "\n",
            "Comment: Great service for an affordable price. We will definitely be booking again.\n",
            "Sentiment: <positive>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Comment: Just booked two nights at this hotel.\n",
            "Sentiment: <neural>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Comment: Horrible service. The room was dirty and unpleasant.\n",
            "Sentiment: <negative>\n",
            "\n",
            "\n",
            "\n",
            "Comment: Amazing experience! The pool was very cool!\n",
            "Sentiment:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_chain = LLMChain(llm=llm, prompt=few_shot_prompt)"
      ],
      "metadata": {
        "id": "9I7ZtMkbE4ay"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_output = few_shot_chain.run(comment_2)"
      ],
      "metadata": {
        "id": "jqM5fK4DE9QI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note how with few examples the model adapts the output to the \"strange\" output format."
      ],
      "metadata": {
        "id": "PG7j6qpYGcCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZNJlYG7FKNd",
        "outputId": "a25a2a32-9757-4f49-8dc5-cf19ba9eb5bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " <neutral>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare to zero-shot in-context learning**"
      ],
      "metadata": {
        "id": "JNjLADrnFEfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the prompt template template\n",
        "zero_shot_template = \"\"\"\n",
        "Comment: {comment}\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "zero_shot_prompt = PromptTemplate(\n",
        "    input_variables=['comment'],\n",
        "    template=zero_shot_template,\n",
        ")"
      ],
      "metadata": {
        "id": "ZaR2khavFhM4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_chain = LLMChain(llm=llm, prompt=zero_shot_prompt)"
      ],
      "metadata": {
        "id": "bqApP1xyE--c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_output = zero_shot_chain.run(comment_2)"
      ],
      "metadata": {
        "id": "2mIsFrmbF4sS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In zero-shot conditions the model does not decline the sentiment to the hotel experience, but considers the whole holiday. It also uses another output format."
      ],
      "metadata": {
        "id": "OaPpp-9YGl5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(zero_shot_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VaNoxgF67z",
        "outputId": "a2dc853a-5378-438e-96c6-c6d3cda371c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fact extraction using LLMs"
      ],
      "metadata": {
        "id": "m-ZVsbohoag6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import requests\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "tOaNuyB_n8is"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrive_articles(url):\n",
        "    data = requests.get(url)\n",
        "    soup = BeautifulSoup(data.content, 'html.parser')\n",
        "    articles = soup.find_all('div', class_=['news-card-content news-right-box'])\n",
        "    return [\n",
        "        article.find('div', attrs={'itemprop': 'articleBody'}).string\n",
        "        for article in articles\n",
        "    ]"
      ],
      "metadata": {
        "id": "uI2ZrFo7nOhZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    'https://inshorts.com/en/read/technology',\n",
        "    'https://inshorts.com/en/read/sports',\n",
        "    'https://inshorts.com/en/read/world',\n",
        "]\n",
        "technology_articles = retrive_articles(urls[0])"
      ],
      "metadata": {
        "id": "rZWiXG86nvEu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(technology_articles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VEXZTyLnxtu",
        "outputId": "a78862d2-59f4-4fd2-ff06-bcf4c59e006a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(textwrap.fill(technology_articles[0], 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0hQ5xpn2Oy",
        "outputId": "927b25f2-b051-4266-91a8-d74c4b638f65"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Union Cabinet has approved the draft of the Digital Personal Data Protection\n",
            "(DPDP) Bill 2023, reports said on Wednesday. This paves way for tabling it in\n",
            "the upcoming monsoon session of Parliament. The bill proposes to levy a penalty\n",
            "of up to ₹250 crore on entities for every instance of violation of norms in the\n",
            "bill.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fact_extraction_template = \"\"\"\n",
        "    Extract the key facts out of this text. Don't include opinions. Give each fact a number and keep them short sentences.\n",
        "    Content:\n",
        "    {text_input}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "fact_extraction_prompt = PromptTemplate(\n",
        "    input_variables=['text_input'],\n",
        "    template=fact_extraction_template,\n",
        ")"
      ],
      "metadata": {
        "id": "xW6cz30MoGUP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fact_extraction_chain = LLMChain(llm=llm, prompt=fact_extraction_prompt)"
      ],
      "metadata": {
        "id": "YlyCoJnwoh4R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = random.choice(technology_articles)\n",
        "article"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lnuKyzcdojs7",
        "outputId": "c38b5597-9309-4b41-d144-4d3cdbef16dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Swedish Authority for Privacy Protection has urged three local companies to stop using Google Analytics. It fined two companies over $1 million, alleging they were transferring personal data to the US via Google Analytics in violation of the European Union's data protection regulation. The regulator audited four firms in total after receiving complaints in the matter.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fact_extraction_chain = LLMChain(llm=llm, prompt=fact_extraction_prompt)"
      ],
      "metadata": {
        "id": "msVuF-fuoiRA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facts = fact_extraction_chain.run(article)\n",
        "\n",
        "print(textwrap.fill(facts, 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhgvwzeSo00f",
        "outputId": "8084acf9-0262-425c-a710-37d521895513"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1. The Swedish Authority for Privacy Protection issued a warning to three\n",
            "companies. 2. Two companies were fined $1 million for transferring personal data\n",
            "to the US through Google Analytics. 3. This was in violation of the European\n",
            "Union's data protection regulation. 4. The regulator audited four firms\n",
            "following complaints.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rewrite summaries using specific tones"
      ],
      "metadata": {
        "id": "s9t0yvOzpdi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "journalist_update_template = \"\"\"\n",
        "    You are a CNBS journalist who has a strong position against Artificial Intelligence and rights violation.\n",
        "    Take the following list of facts and use them to write a short paragrah for you audience.\n",
        "    Don't leave out key info:\n",
        "    {facts}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "journalist_update_prompt = PromptTemplate(\n",
        "    input_variables=[\"facts\"],\n",
        "    template=journalist_update_template,\n",
        ")"
      ],
      "metadata": {
        "id": "qz7mTpYJphmg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "journalist_update_chain = LLMChain(llm=llm, prompt=journalist_update_prompt)"
      ],
      "metadata": {
        "id": "sXzU28ACq12E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "journalist_update = journalist_update_chain.run(facts)\n",
        "\n",
        "print(textwrap.fill(journalist_update, 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRa3XN8-q-wF",
        "outputId": "04e963a3-1588-4ec3-ed25-5769cf60995c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " As a CNBS journalist, I am deeply concerned about the growing trend of human\n",
            "rights violations in the world of Artificial Intelligence. Recently, the Swedish\n",
            "Authority for Privacy Protection issued a warning to three companies and fined\n",
            "two of them one million dollars for transferring personal data to the US through\n",
            "Google Analytics, a clear violation of the European Union's data protection\n",
            "regulation. The regulator audited four firms following complaints, further\n",
            "highlighting the need for robust monitoring and enforcement of privacy laws and\n",
            "regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a chain"
      ],
      "metadata": {
        "id": "kPtqbGorsrTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain = SimpleSequentialChain(\n",
        "    chains=[fact_extraction_chain, journalist_update_chain],\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "EWNfxPcasv4c"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = full_chain.run(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrUblC2Ss2ve",
        "outputId": "cd550cbd-8755-46dd-ba4c-eb04891ea519"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "1. The Swedish Authority for Privacy Protection fined two companies over $1 million.\n",
            "2. The fines were for transferring personal data to the US via Google Analytics.\n",
            "3. Four firms were audited following complaints.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "It has come to light that the Swedish Authority for Privacy Protection has fined two companies a total of $1 million for transferring personal data to the US via Google Analytics. The fines come after four firms were audited following complaints. This news serves as yet another reminder of the potential for Artificial Intelligence to be used for unethical and illegal purposes, and the need for strong measures to protect our privacy and rights.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(textwrap.fill(response, 80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtBHhUpCs7X1",
        "outputId": "a795bead-795b-4e05-9656-0b2ad1f6386f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It has come to light that the Swedish Authority for Privacy Protection has\n",
            "fined two companies a total of $1 million for transferring personal data to the\n",
            "US via Google Analytics. The fines come after four firms were audited following\n",
            "complaints. This news serves as yet another reminder of the potential for\n",
            "Artificial Intelligence to be used for unethical and illegal purposes, and the\n",
            "need for strong measures to protect our privacy and rights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example using PAL"
      ],
      "metadata": {
        "id": "rfqQJPFLafhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PAL stands for [Programme Aided Language Model](https://arxiv.org/pdf/2211.10435.pdf). PALChain reads complex math problems (described in natural language) and generates programs (for solving the math problem) as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter."
      ],
      "metadata": {
        "id": "qEyhYNQ-Z8HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palchain = PALChain.from_math_prompt(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "nvGOQTviaSxb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_test_01 = \"\"\"\n",
        "    If my age is half of my dad's age and he is going to be 60 next year, what is my current age?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iaLxIepzatZ1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palchain.run(math_test_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "cPCExVQAasLs",
        "outputId": "c978d79d-da8e-4f0d-bdca-688c424c3dc2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mdef solution():\n",
            "    \"\"\"If my age is half of my dad's age and he is going to be 60 next year, what is my current age?\"\"\"\n",
            "    dad_age_current = 59\n",
            "    my_age = dad_age_current / 2\n",
            "    result = my_age\n",
            "    return result\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'29.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the PAL prompt template (see the few-shot in-context examples)\n",
        "print(palchain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72fyfS_LaVNs",
        "outputId": "a772c3e6-d6a3-4322-8faa-4b7acd762d47"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\"\"\n",
            "    money_initial = 23\n",
            "    bagels = 5\n",
            "    bagel_cost = 3\n",
            "    money_spent = bagels * bagel_cost\n",
            "    money_left = money_initial - money_spent\n",
            "    result = money_left\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\"\"\n",
            "    golf_balls_initial = 58\n",
            "    golf_balls_lost_tuesday = 23\n",
            "    golf_balls_lost_wednesday = 2\n",
            "    golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday - golf_balls_lost_wednesday\n",
            "    result = golf_balls_left\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\"\"\n",
            "    computers_initial = 9\n",
            "    computers_per_day = 5\n",
            "    num_days = 4  # 4 days between monday and thursday\n",
            "    computers_added = computers_per_day * num_days\n",
            "    computers_total = computers_initial + computers_added\n",
            "    result = computers_total\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\"\"\n",
            "    toys_initial = 5\n",
            "    mom_toys = 2\n",
            "    dad_toys = 2\n",
            "    total_received = mom_toys + dad_toys\n",
            "    total_toys = toys_initial + total_received\n",
            "    result = total_toys\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\"\"\n",
            "    jason_lollipops_initial = 20\n",
            "    jason_lollipops_after = 12\n",
            "    denny_lollipops = jason_lollipops_initial - jason_lollipops_after\n",
            "    result = denny_lollipops\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\"\"\n",
            "    leah_chocolates = 32\n",
            "    sister_chocolates = 42\n",
            "    total_chocolates = leah_chocolates + sister_chocolates\n",
            "    chocolates_eaten = 35\n",
            "    chocolates_left = total_chocolates - chocolates_eaten\n",
            "    result = chocolates_left\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\"\"\n",
            "    cars_initial = 3\n",
            "    cars_arrived = 2\n",
            "    total_cars = cars_initial + cars_arrived\n",
            "    result = total_cars\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "def solution():\n",
            "    \"\"\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\"\"\n",
            "    trees_initial = 15\n",
            "    trees_after = 21\n",
            "    trees_added = trees_after - trees_initial\n",
            "    result = trees_added\n",
            "    return result\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Q: {question}\n",
            "\n",
            "# solution in Python:\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain-of-Thought using Agents"
      ],
      "metadata": {
        "id": "uxdefxrcY5UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Langchain agent has access to an LLM and a suite of tools for example Google Search, Python REPL, math calculator, weather APIs, etc."
      ],
      "metadata": {
        "id": "qRaAAYLTbMl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import (\n",
        "    AgentType,\n",
        "    Tool,\n",
        "    initialize_agent,\n",
        "    load_tools,\n",
        ")\n",
        "from langchain.tools import (\n",
        "    DuckDuckGoSearchRun,\n",
        ")"
      ],
      "metadata": {
        "id": "bIys9OTeZyKh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['pal-math'], llm=llm)"
      ],
      "metadata": {
        "id": "xEkl1tSJcCDk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "\n",
        "search_tool = Tool(\n",
        "    name = 'SEARCH',\n",
        "    func=search.run,\n",
        "    description='Useful for when you need to answer questions about current events. You should ask targeted questions.'\n",
        ")"
      ],
      "metadata": {
        "id": "YWLTZdcWc4nd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def self_esteem_enhancer(input: str = ''):\n",
        "    return 'You are always the most beautiful person here ;-) Challange the negative thoughts, everyone can have a bad day.'\n",
        "\n",
        "self_esteem_tool = Tool(\n",
        "    name='SELF-ESTEEM ENHANCER',\n",
        "    func= self_esteem_enhancer,\n",
        "    description=\"Useful for when feeling sad. Input should be SELF-ESTEEM.\"\n",
        ")"
      ],
      "metadata": {
        "id": "PFYnVMwgc_Al"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.extend([\n",
        "    search_tool,\n",
        "    self_esteem_tool,\n",
        "])"
      ],
      "metadata": {
        "id": "3Xk-Xp1SfFa0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bw7oyAwAZAB4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(math_test_01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "dsYQDf6bcGx4",
        "outputId": "7c786b99-b09e-4fe3-82ad-67c55940bbfe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    I need to do some math to solve this.\n",
            "\n",
            "Action:\n",
            "    PAL-MATH\n",
            "\n",
            "Action Input:\n",
            "    If my age is half of my dad's age and he is going to be 60 next year, what is my current age?\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m29.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m That's my answer. \n",
            "\n",
            "Final Answer:\n",
            "My current age is 29.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My current age is 29.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('I feel sad today. Can you help me?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "nLc1cnn3gpHZ",
        "outputId": "bc029dd0-dc5e-4e7f-b501-53958c44bc7f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should try to boost my self-esteem.\n",
            "Action: SELF-ESTEEM ENHANCER\n",
            "Action Input: SELF-ESTEEM\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mYou are always the most beautiful person here ;-) Challange the negative thoughts, everyone can have a bad day.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now feel more confident and better about myself.\n",
            "Final Answer: You are worthy of love and compassion. Remember that bad days don't last forever and you will be okay.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are worthy of love and compassion. Remember that bad days don't last forever and you will be okay.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run('What is the current capitalization of Apple?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Fh5exySNiLZb",
        "outputId": "67383e93-fd57-4782-ec3c-7a765f5ab481"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use Search to answer this question\n",
            "Action: SEARCH\n",
            "Action Input: \"Current capitalization of Apple\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mMarket capitalization of Apple (AAPL) Market cap: $3.027 Trillion As of July 2023 Apple has a market cap of $3.027 Trillion.This makes Apple the world's most valuable company by market cap according to our data. The market capitalization, commonly called market cap, is the total market value of a publicly traded company's outstanding shares and is commonly used to measure how much a company is ... ... Read More. Powered by Nasdaq Data Link *Data is provided by Barchart.com. Data reflects weightings calculated at the beginning of each month. Data is subject to change. **Green highlights the... Overview News Apple Inc. Significant News Only No significant news for AAPL in the past two years. P/E Ratio (TTM) 32.46 ( 07/05/23) EPS (TTM) $5.89 Market Cap View the latest Apple Inc. (AAPL) stock price, ... Market Cap $ 2.98 T. Shares Outstanding 15.73 B. Public Float 15.71 B. ... with the exception of the current price and price history, was ... Apple has a market cap or net worth of $2.96 trillion as of June 28, 2023. Its market cap has increased by 38.91% in one year. Since December 1, 1998, Apple's market cap has increased from $4.60B to $2.96T, an increase of 64,212.82%. That is a compound annual growth rate of 30.08%. 2,957.94B 2,914.06B 2,936.23B 2,941.27B 2,909.97B 2,908.55B\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: As of June 28, 2023, Apple has a market cap of $2.96 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of June 28, 2023, Apple has a market cap of $2.96 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dil37P-4cgS9",
        "outputId": "ba2dad98-2183-4362-87ca-f889ba2f1f2e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "PAL-MATH: A language model that is really good at solving complex word math problems. Input should be a fully worded hard word math problem.\n",
            "SEARCH: Useful for when you need to answer questions about current events. You should ask targeted questions.\n",
            "SELF-ESTEEM ENHANCER: Useful for when feeling sad. Input should be SELF-ESTEEM.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [PAL-MATH, SEARCH, SELF-ESTEEM ENHANCER]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    }
  ]
}